{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b052ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_processing.py\n",
    "from typing import List, Sequence, Union\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "from feature_lists import DATASET_TO_FEATURE\n",
    "\n",
    "def get_feature_list(dataset:str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Accept either a preset name (str) or an explicit ordered list of feature keys.\n",
    "    Returns a concrete list of feature names in the order they should be used.\n",
    "    \"\"\"\n",
    "    if dataset in DATASET_TO_FEATURE:\n",
    "        return DATASET_TO_FEATURE[dataset]\n",
    "    raise ValueError(\n",
    "        f\"Unknown feature selection '{dataset}'. \"\n",
    "        f\"Use one of {list(DATASET_TO_FEATURE.keys())} or pass a list of fields.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _default_value_for(feature_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Choose a safe numeric default for missing values.\n",
    "    - RSSI-like quantities default to -100 dBm-ish.\n",
    "    - Shares/ratios/power ratios and scalars default to 0.0.\n",
    "    \"\"\"\n",
    "    name = feature_name.lower()\n",
    "    if \"_rssi\" in name or \"_rssi_1m\" in name or \"residual\" in name:\n",
    "        return -100.0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    collection_name: str,\n",
    "    db_name: str,\n",
    "    features: Union[str, Sequence[str]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Load data from MongoDB and return a NumPy array where each row is:\n",
    "        [ <features...>, location_x, location_y ]\n",
    "\n",
    "    feature_selection: preset name or explicit list of fields (order = model input order)\n",
    "    \"\"\"\n",
    "\n",
    "    client = MongoClient(\n",
    "        \"mongodb://localhost:28910/\",\n",
    "        connectTimeoutMS=30000,\n",
    "        socketTimeoutMS=30000,\n",
    "        maxPoolSize=20,\n",
    "    )\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    # Build projection: computed fields via $ifNull to guarantee numeric values.\n",
    "    projection = {\n",
    "        \"location_x\": 1,\n",
    "        \"location_y\": 1,\n",
    "    }\n",
    "    for f in features:\n",
    "        projection[f] = {\"$ifNull\": [f\"${f}\", _default_value_for(f)]}\n",
    "\n",
    "    # Keep only rows with numeric labels; features are numeric due to $ifNull above.\n",
    "    pipeline = [\n",
    "        {\"$project\": projection},\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"location_x\": {\"$type\": \"number\"},\n",
    "                \"location_y\": {\"$type\": \"number\"},\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    cursor = collection.aggregate(pipeline, allowDiskUse=True, batchSize=50000)\n",
    "    rows = []\n",
    "    first_doc = None\n",
    "    for doc in cursor:\n",
    "\n",
    "        if not first_doc:\n",
    "            first_doc = doc\n",
    "        try:\n",
    "            x = [float(doc[f]) for f in features]\n",
    "            y = [float(doc[\"location_x\"]), float(doc[\"location_y\"])]\n",
    "            rows.append(tuple(x + y))\n",
    "        except Exception:\n",
    "            # Skip malformed rows\n",
    "            continue\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(f\"No valid data found in collection '{collection_name}' of DB '{db_name}'.\")\n",
    "\n",
    "    return first_doc, np.array(rows, dtype=np.float32)\n",
    "\n",
    "\n",
    "def split_combined_data(\n",
    "    combined_array: np.ndarray,\n",
    "    features: Union[str, Sequence[str]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Split stacked array into (X, y) based on the selected feature list size.\n",
    "    \"\"\"\n",
    "    n_features = len(features)\n",
    "    X = combined_array[:, :n_features]\n",
    "    y = combined_array[:, n_features:]  # [location_x, location_y]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def combine_arrays(arrays: List[np.ndarray]) -> np.ndarray:\n",
    "    return np.vstack(arrays)\n",
    "\n",
    "\n",
    "def shuffle_array(arr: np.ndarray, random_state: int = None) -> np.ndarray:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    idx = np.arange(arr.shape[0])\n",
    "    rng.shuffle(idx)\n",
    "    return arr[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455b4634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§° Database in use: wifi_fingerprinting_data_extra_features\n",
      "Features: ['freind1_rssi_rssi_1m', 'freind2_rssi_rssi_1m', 'freind3_rssi_rssi_1m', 'freind1_rssi_residual', 'freind2_rssi_residual', 'freind3_rssi_residual', 'freind1_rssi', 'freind2_rssi', 'freind3_rssi', 'freind1_rssi_power_over_freind2_rssi', 'freind1_rssi_power_over_freind3_rssi', 'freind2_rssi_power_over_freind1_rssi', 'freind2_rssi_power_over_freind3_rssi', 'freind3_rssi_power_over_freind1_rssi', 'freind3_rssi_power_over_freind2_rssi', 'freind1_rssi_share', 'freind2_rssi_share', 'freind3_rssi_share', 'beta1_log10d', 'n_est', 'freind1_rssi_over_freind2_rssi', 'freind1_rssi_over_freind3_rssi', 'freind2_rssi_over_freind1_rssi', 'freind2_rssi_over_freind3_rssi', 'freind3_rssi_over_freind1_rssi', 'freind3_rssi_over_freind2_rssi']\n",
      "First entry\n",
      "{'_id': ObjectId('68af04c4c6f1e3ca30a27ead'), 'location_x': 0.5, 'location_y': -0.03333333333333327, 'freind1_rssi_rssi_1m': -59.95480661269403, 'freind2_rssi_rssi_1m': -78.26277706703974, 'freind3_rssi_rssi_1m': -75.15790581173023, 'freind1_rssi_residual': 11.040512507266044, 'freind2_rssi_residual': -6.0100866075172235, 'freind3_rssi_residual': -4.295626717086407, 'freind1_rssi': -60.0, 'freind2_rssi': -77.0, 'freind3_rssi': -75.0, 'freind1_rssi_power_over_freind2_rssi': 50.11872336272725, 'freind1_rssi_power_over_freind3_rssi': 31.622776601683793, 'freind2_rssi_power_over_freind1_rssi': 0.01995262314968879, 'freind2_rssi_power_over_freind3_rssi': 0.630957344480193, 'freind3_rssi_power_over_freind1_rssi': 0.03162277660168379, 'freind3_rssi_power_over_freind2_rssi': 1.5848931924611143, 'freind1_rssi_share': 0.950954159099227, 'freind2_rssi_share': 0.01897402996913608, 'freind3_rssi_share': 0.03007181093163692, 'beta1_log10d': -2.4150476156048573, 'n_est': 0.24150476156048573, 'freind1_rssi_over_freind2_rssi': 0.7792207792207793, 'freind1_rssi_over_freind3_rssi': 0.8, 'freind2_rssi_over_freind1_rssi': 1.2833333333333334, 'freind2_rssi_over_freind3_rssi': 1.0266666666666666, 'freind3_rssi_over_freind1_rssi': 1.25, 'freind3_rssi_over_freind2_rssi': 0.974025974025974}\n",
      "For first data entry we can see features and labels\n",
      "[-5.9954807e+01 -7.8262779e+01 -7.5157906e+01  1.1040512e+01\n",
      " -6.0100865e+00 -4.2956266e+00 -6.0000000e+01 -7.7000000e+01\n",
      " -7.5000000e+01  5.0118725e+01  3.1622776e+01  1.9952623e-02\n",
      "  6.3095737e-01  3.1622775e-02  1.5848932e+00  9.5095414e-01\n",
      "  1.8974030e-02  3.0071812e-02 -2.4150476e+00  2.4150476e-01\n",
      "  7.7922076e-01  8.0000001e-01  1.2833333e+00  1.0266666e+00\n",
      "  1.2500000e+00  9.7402596e-01]\n",
      "[ 0.5        -0.03333334]\n"
     ]
    }
   ],
   "source": [
    "db_name = \"wifi_fingerprinting_data_extra_features\"\n",
    "\n",
    "feature_list = get_feature_list(db_name)\n",
    "\n",
    "all_collections = [\n",
    "    \"equilatero_grande_garage\",\n",
    "    \"equilatero_grande_outdoor\",\n",
    "    \"equilatero_medio_garage\",\n",
    "    \"equilatero_medio_outdoor\",\n",
    "    \"isosceles_grande_indoor\",\n",
    "    \"isosceles_grande_outdoor\",\n",
    "    \"isosceles_medio_outdoor\",\n",
    "    \"obtusangulo_grande_outdoor\",\n",
    "    \"obtusangulo_pequeno_outdoor\",\n",
    "    \"reto_grande_garage\",\n",
    "    \"reto_grande_indoor\",\n",
    "    \"reto_grande_outdoor\",\n",
    "    \"reto_medio_garage\",\n",
    "    \"reto_medio_outdoor\",\n",
    "    \"reto_n_quadrado_grande_indoor\",\n",
    "    \"reto_n_quadrado_grande_outdoor\",\n",
    "    \"reto_n_quadrado_pequeno_outdoor\",\n",
    "    \"reto_pequeno_garage\",\n",
    "    \"reto_pequeno_outdoor\",\n",
    "]\n",
    "\n",
    "print(f\"ðŸ§° Database in use: {db_name}\")\n",
    "# Uncomment to see the exact feature order:\n",
    "print(\"Features:\", feature_list)\n",
    "\n",
    "# ---- Training data\n",
    "first_entry, train_datasets = get_dataset(\"equilatero_grande_garage\", db_name, feature_list)\n",
    "#combined_train = combine_arrays(train_datasets)\n",
    "#shuffled_train = shuffle_array(combined_train)\n",
    "features, labels = split_combined_data(train_datasets, feature_list)\n",
    "\n",
    "\n",
    "print(\"First entry\")\n",
    "print(first_entry)\n",
    "print(\"For first data entry we can see features and labels\")\n",
    "print(features[0])\n",
    "print(labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "location-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
